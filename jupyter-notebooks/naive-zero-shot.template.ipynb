{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "983107d5-7273-4ad7-8dee-7ac7e469297c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /home/james/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: openai in /home/james/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /home/james/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/james/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /home/james/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/james/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from requests>=2.20->openai) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/james/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/james/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/james/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/james/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/james/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/james/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/james/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/james/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/james/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from aiohttp->openai) (1.3.1)\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/src/valuestreamai/molecule-semantic-search/jupyter-notebooks/boilerplate.py:43\u001b[0m\n\u001b[1;32m     37\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# In[7]:\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[43mgpt4\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# ## Llama2 Setup\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# ### Install libraries\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# In[6]:\u001b[39;00m\n\u001b[1;32m     53\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall langchain huggingface_hub chainlit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/src/valuestreamai/molecule-semantic-search/jupyter-notebooks/boilerplate.py:28\u001b[0m, in \u001b[0;36mgpt4\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgpt4\u001b[39m(prompt):\n\u001b[0;32m---> 28\u001b[0m \tcompletion \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m      \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful assistant.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m      \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprompt\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages/openai/api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    766\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    767\u001b[0m     )\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys."
     ]
    }
   ],
   "source": [
    "%run \"boilerplate.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32927043-b5de-44b1-83c2-59d9813f440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_pager = \"\"\"\n",
    "﻿Proof of Concept Proposal: Automated Ontologization for Heterogeneous Experimental Data\n",
    "Toby Tobkin - Solutions Architect - toby@valuestream.ai\n",
    "\n",
    "\n",
    "Prepared for Forschungszentrum Jülich Department of AI and Data Analytics for Integrated Clean Energy Technologies\n",
    "Background\n",
    "A primary barrier to the widespread adoption of clean hydrogen fuel storage is discovering a practical material for Hydrogen Energy Devices. At the current rate of materials science advancement, some experts project that the discovery and adoption of requisite advanced materials such as catalysts and membrane materials could take until 2050. However, climate change and pollution are occurring rapidly, so it is critical to accelerate this R&D timeframe to 2035. The most significant barrier to accelerating this timeframe is the quantity of researcher toil required per cycle of advanced materials science (AES) experiments. The primary root cause of researcher toil is the human-inaccessibility of experimental data from applied energy materials research. This inaccessibility exists because no widely adopted ontology exists for applied energy materials research. Thus, experimental data is stored heterogeneously, effectively siloed data between scientific domains and individual labs. To overcome this, material scientists must manually de-silo from tens of millions of data points about materials and fabrication methods, drastically slowing down applied materials research. Due to intractable issues such as lab researcher turnover, we presume that AES data will remain heterogeneous without Practical Automated Ontologization for AES Heterogeneous Experimental Data (HED).\n",
    "\n",
    "\n",
    "Forschungszentrum Jülich Department of AI and Data Analytics for Integrated Clean Energy Technologies seeks research advancements to commercialize practical, clean hydrogen fuel storage. ValuestreamAI seeks a challenging, impactful engineering problem to solve.\n",
    "Programming Competition Venue & Scope\n",
    "The ValuestreamAI team will compete in the 2023 Samsung Gen AI programming competition in San Francisco.  The team comprises three engineers and one technical business analyst. Approximately one week of engineering preparation work is done prior to the competition. The competition is approximately ten hours of execution time. Thus, the scope must be limited while still shipping a usable product.\n",
    "Problem Statement\n",
    "Automate the classification of non-standardized CSV headers to Node Labels compliant with the Proposed EMMO Extension Ontology for Hydrogen Energy Conversion Materials Science. \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "Problem Selection Rationale\n",
    "Header Classification to Node Label was chosen because it is a microcosm of the AES HED problem.\n",
    "\n",
    "\n",
    "The problem was selected using the following process:\n",
    "1. The Client research team presented several relevant research problems. \n",
    "2. Sort by urgency to solve\n",
    "3. Tie-break by the impact of solving\n",
    "4. Filter by:\n",
    "   1. Estimated analysis scope under 70 hours\n",
    "   2. Estimated implementation scope under 30 hours\n",
    "\n",
    "\n",
    "Given additional time, we may also proof of concept Node Attribute classification.\n",
    "________________\n",
    "KPIs\n",
    "ValuestreamAI seeks to choose KPIs that are an accurate proxy for implementing Practical Automated Ontologization for AES HED. The following KPIs were chosen:\n",
    "\n",
    "\n",
    "Precision\n",
    "\tPrecision of the classifier is paramount because a human user will distrust the inference system if they feel they cannot trust positive inferences\n",
    "\tRecall\n",
    "\tRecall determines the percent of researcher toil automated for the given subtask\n",
    "\tConfusion Matrix\n",
    "\tA slideshow-friendly version of Precision and Recall.\n",
    "\n",
    "\n",
    "\t  \n",
    "\n",
    "\tRuntime Cost Per Million Rows\n",
    "\tDetermines the ongoing per-unit cost of testing and using the inference pipeline\n",
    "\tR&D Costs\n",
    "\tThe upfront costs. There should be an attainable cost curve for achieving useful milestones.\n",
    "\tLicensing Costs\n",
    "\tCosts related to licensing technology\n",
    "\tSuitability for On-prem Cluster\n",
    "\tHow compatible is the solution with the client research team's compute cluster?\n",
    "\tData Privacy\n",
    "\tIs data processed and stored in a secure manner that is verifyable by a layman?\n",
    "\tClient Satisfaction\n",
    "\tDoes the deliverable satisfy its intended purpose?\n",
    "\tSolution Constraints\n",
    "The proposed solution must:\n",
    "* Represent the larger problem of Practical Automated Ontologization for AES HED\n",
    "* Plausibly scale to reduce a top category of researcher toil by at least 90%\n",
    "* Be adaptable to support high-quality integration with neo4j and VIMI\n",
    "________________\n",
    "Hackathon Proposed Deliverables\n",
    "The deliverable is a Github Repo with the following contents:\n",
    "Jupyter Notebooks\n",
    "\tPython notebooks that reproduce the inference experiments for the problem under study.\n",
    "\tDevelopment Environment\n",
    "\tEnglish instructions and Linux scripts documenting how to reproduce the desktop environment for reproducing or extending the experiments delivered.\n",
    "\tWorkflows\n",
    "\tEnglish instructions and Linux scripts documenting how to reproduce or extend the experiments delivered.\n",
    "\tLive Training Recording\n",
    "\tUp to three hours of recorded live sessions for the client research team for training and analysis.\n",
    "\t\n",
    "\n",
    "The deliverable will have the following attributes: 1. Complementary to existing work, 2. MIT license, 3. High standard of readability\n",
    "Payment Terms\n",
    "ValuestreamAI requests payment only if the deliverable meets or exceeds the client research team's expectations. Payment shall be due NET60 from the day of invoice to the client research team. The requested payment amount is the approximate cost of competition preparation and travel expenses, CAD$4000. Engineering hours are granted pro bono for this project.\n",
    "Future Work\n",
    "The proposed deliverable is only a small slice of the larger problem of Practical Automated Ontologization for AES HED. The ValuestreamAI team is in the early stages of understanding the broader context of this research field. However, they understand the following future work is required:\n",
    "* Defining the complete engineering scope of Practical Automated Ontologization for AES HED\n",
    "* Inferring ontological relationships between heterogeneous data fields\n",
    "* Investigating the potential for collaboration with other research institutions to pool resources and data\n",
    "* Evaluating the effectiveness of the ontology in practice and making necessary adjustments based on feedback from researchers\n",
    "* Exploring the potential for machine learning algorithms to predict outcomes based on the AES data\n",
    "Jargon and Entities\n",
    "AES: Advanced Materials Science.\n",
    "\n",
    "\n",
    "HED: Heterogeneous Experimental Data.\n",
    "\n",
    "\n",
    "AES HED: The subproblem under research.\n",
    "\n",
    "\n",
    "Hydrogen Energy Devices: Water electrolyzers and fuel cells.\n",
    "\n",
    "\n",
    "FAIR: Findable, Accessible, Interoperable, and Reusable\n",
    "\n",
    "\n",
    "neo4j: an industry-standard graph database\n",
    "\n",
    "\n",
    "EMMO: EMMO, or the European Materials Modelling Ontology, is a versatile ontology for materials sciences developed by the European Materials Modelling Council. It consists of three levels: the top level defines real-world objects and introduces \"perspectives\" to reflect their pluralistic nature, the middle level contains specific perspectives that make EMMO applicable to various domains, and the bottom level contains ontologies of specific materials science domains. EMMO is used to standardize the knowledge representation of a domain, making it particularly useful in the context of FAIR (Findable, Accessible, Interoperable, Reusable) data generation.\n",
    "\n",
    "\n",
    "VIMI:  Virtual Materials Intelligence platform, is a system that integrates data-driven methods for materials science research. It uses the Python framework Django for seamless integration and data management. The platform is designed to handle data from fabrication workflows, measurements, and simulations and encourages researchers to share data to accelerate their research. VIMI is particularly useful in the field of energy materials, where it can assist in the screening of materials, experimental design, the optimization of workflows, and the orchestration of devices within self-driven labs. VIMI is a spin-off Project from the Institute of Energy and Climate Research, IEK-13 at Forschungszentrum Juelich.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fafdc7c-946f-4027-93c9-0bf81e5e9fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = f\"\"\"\n",
    "What sections should be in a proof of concept notebook for doing zero-shot prediction of materials science ontology classes from experimental csv data headers?\n",
    "\n",
    "For context, the engineering proposal is given in <one-pager>\n",
    "\n",
    "<one-pager>\n",
    "{one_pager}\n",
    "</one-pager>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56b5f67-029e-4dc7-97a7-3b1075b536bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_md(gpt4(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1179d-92ae-4ac0-86de-05da580d3feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_md(llama2(input))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
