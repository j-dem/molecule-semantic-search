{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPeAm8n6cM5Z"
   },
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEgix9HRdzAL"
   },
   "source": [
    "## OpenAI Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9cyllKO2bsfC",
    "outputId": "37081927-cd58-4b65-dc33-eda50c668630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (0.28.0)\n",
      "Requirement already satisfied: python-dotenv in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: requests>=2.20 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from requests>=2.20->openai) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from requests>=2.20->openai) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from aiohttp->openai) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai python-dotenv\n",
    "\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key from .env\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def gpt4(prompt):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{prompt}\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (0.0.299)\n",
      "Requirement already satisfied: huggingface_hub in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (0.17.2)\n",
      "Requirement already satisfied: python-dotenv in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: chainlit in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from langchain) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: anyio<4.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.38 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from langchain) (0.0.40)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from langchain) (2.8.6)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from langchain) (1.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: filelock in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from huggingface_hub) (3.12.4)\n",
      "Requirement already satisfied: fsspec in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from huggingface_hub) (2023.9.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from huggingface_hub) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from huggingface_hub) (23.1)\n",
      "Requirement already satisfied: aiofiles<24.0.0,>=23.1.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from chainlit) (23.2.1)\n",
      "Requirement already satisfied: asyncer<0.0.3,>=0.0.2 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from chainlit) (0.0.2)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from chainlit) (8.1.7)\n",
      "Requirement already satisfied: fastapi<0.100.0,>=0.99.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from chainlit) (0.99.1)\n",
      "Requirement already satisfied: fastapi-socketio<0.0.11,>=0.0.10 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from chainlit) (0.0.10)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from chainlit) (1.2.0)\n",
      "Requirement already satisfied: lazify<0.5.0,>=0.4.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from chainlit) (0.4.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.6 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from chainlit) (1.5.8)\n",
      "Requirement already satisfied: prisma<0.11.0,>=0.10.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from chainlit) (0.10.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.8.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from chainlit) (2.8.0)\n",
      "Requirement already satisfied: python-graphql-client<0.5.0,>=0.4.3 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from chainlit) (0.4.3)\n",
      "Requirement already satisfied: python-multipart<0.0.7,>=0.0.6 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from chainlit) (0.0.6)\n",
      "Requirement already satisfied: syncer<3.0.0,>=2.0.3 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from chainlit) (2.0.3)\n",
      "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from chainlit) (2.0.1)\n",
      "Requirement already satisfied: uptrace<2.0.0,>=1.18.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from chainlit) (1.20.0)\n",
      "Requirement already satisfied: uvicorn<0.24.0,>=0.23.2 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from chainlit) (0.23.2)\n",
      "Requirement already satisfied: watchfiles<0.21.0,>=0.20.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from chainlit) (0.20.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from fastapi<0.100.0,>=0.99.0->chainlit) (0.27.0)\n",
      "Requirement already satisfied: python-socketio>=4.6.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from fastapi-socketio<0.0.11,>=0.0.10->chainlit) (5.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: httpx>=0.19.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from prisma<0.11.0,>=0.10.0->chainlit) (0.25.0)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from prisma<0.11.0,>=0.10.0->chainlit) (3.1.2)\n",
      "Requirement already satisfied: tomlkit in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from prisma<0.11.0,>=0.10.0->chainlit) (0.12.1)\n",
      "Requirement already satisfied: nodeenv in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from prisma<0.11.0,>=0.10.0->chainlit) (1.8.0)\n",
      "Requirement already satisfied: websockets>=5.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from python-graphql-client<0.5.0,>=0.4.3->chainlit) (11.0.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: opentelemetry-api==1.20.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from uptrace<2.0.0,>=1.18.0->chainlit) (1.20.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp==1.20.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from uptrace<2.0.0,>=1.18.0->chainlit) (1.20.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.40b0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from uptrace<2.0.0,>=1.18.0->chainlit) (0.40b0)\n",
      "Requirement already satisfied: opentelemetry-sdk==1.20.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from uptrace<2.0.0,>=1.18.0->chainlit) (1.20.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from opentelemetry-api==1.20.0->uptrace<2.0.0,>=1.18.0->chainlit) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from opentelemetry-api==1.20.0->uptrace<2.0.0,>=1.18.0->chainlit) (6.8.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.20.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp==1.20.0->uptrace<2.0.0,>=1.18.0->chainlit) (1.20.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.20.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp==1.20.0->uptrace<2.0.0,>=1.18.0->chainlit) (1.20.0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.40b0->uptrace<2.0.0,>=1.18.0->chainlit) (66.1.1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.40b0->uptrace<2.0.0,>=1.18.0->chainlit) (1.15.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.41b0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from opentelemetry-sdk==1.20.0->uptrace<2.0.0,>=1.18.0->chainlit) (0.41b0)\n",
      "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.20.0->opentelemetry-exporter-otlp==1.20.0->uptrace<2.0.0,>=1.18.0->chainlit) (2.2.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.20.0->opentelemetry-exporter-otlp==1.20.0->uptrace<2.0.0,>=1.18.0->chainlit) (1.60.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.20.0->opentelemetry-exporter-otlp==1.20.0->uptrace<2.0.0,>=1.18.0->chainlit) (1.58.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.20.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.20.0->opentelemetry-exporter-otlp==1.20.0->uptrace<2.0.0,>=1.18.0->chainlit) (1.20.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.20.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.20.0->opentelemetry-exporter-otlp==1.20.0->uptrace<2.0.0,>=1.18.0->chainlit) (1.20.0)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.19 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from opentelemetry-proto==1.20.0->opentelemetry-exporter-otlp-proto-grpc==1.20.0->opentelemetry-exporter-otlp==1.20.0->uptrace<2.0.0,>=1.18.0->chainlit) (4.24.3)\n",
      "Requirement already satisfied: h11>=0.8 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from uvicorn<0.24.0,>=0.23.2->chainlit) (0.14.0)\n",
      "Requirement already satisfied: httpcore<0.19.0,>=0.18.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from httpx>=0.19.0->prisma<0.11.0,>=0.10.0->chainlit) (0.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from jinja2>=2.11.2->prisma<0.11.0,>=0.10.0->chainlit) (2.1.3)\n",
      "Requirement already satisfied: bidict>=0.21.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit) (0.22.1)\n",
      "Requirement already satisfied: python-engineio>=4.7.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit) (4.7.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api==1.20.0->uptrace<2.0.0,>=1.18.0->chainlit) (3.17.0)\n",
      "Requirement already satisfied: simple-websocket>=0.10.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from python-engineio>=4.7.0->python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit) (0.10.1)\n",
      "Requirement already satisfied: wsproto in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from simple-websocket>=0.10.0->python-engineio>=4.7.0->python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (8.1.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from ipywidgets) (8.15.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from ipywidgets) (5.10.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: backcall in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain huggingface_hub python-dotenv chainlit\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "%pip install ipywidgets # Update ipywidgets to include IProgress\n",
    "\n",
    "from langchain import HuggingFaceHub  # Access LLMs from Hugging Face Hub\n",
    "\n",
    "from langchain import LLMChain, PromptTemplate # For prompt chaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lo8PHALdlH8Q"
   },
   "source": [
    "## Pretty Print Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghU_8yovpoxu"
   },
   "source": [
    "### Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "wDwCWNwYpnea",
    "outputId": "b41d3043-15c2-4216-c557-1fb393a2fb16"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "###### This is a heading\n",
       "####### This is a sub-heading\n",
       "\n",
       "- This is a list item\n",
       "- Another list item\n",
       "\n",
       "**Bold Text**\n",
       "\n",
       "*Italic Text*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def display_md(markdown_string):\n",
    "    display(Markdown(markdown_string))\n",
    "\n",
    "# Usage\n",
    "markdown_content = \"\"\"\n",
    "###### This is a heading\n",
    "####### This is a sub-heading\n",
    "\n",
    "- This is a list item\n",
    "- Another list item\n",
    "\n",
    "**Bold Text**\n",
    "\n",
    "*Italic Text*\n",
    "\"\"\"\n",
    "\n",
    "display_md(markdown_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwN1dXCnlZv3"
   },
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "PGpvc0ErlGqN",
    "outputId": "e7b2922b-59e7-475d-f289-1184ee5be4da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1 col2  col3\n",
       "0     1    a   4.5\n",
       "1     2    b   4.6\n",
       "2     3    c   5.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from IPython.display import display\n",
    "\n",
    "def display_csv(csv_string):\n",
    "    try:\n",
    "        csv_buffer = StringIO(csv_string)\n",
    "        df = pd.read_csv(csv_buffer)\n",
    "\n",
    "        # Simply displaying the DataFrame will render it as a table\n",
    "        display(df)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"The CSV data is empty.\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(\"Could not parse the string as a CSV.\")\n",
    "\n",
    "# Usage\n",
    "# Replace 'your_csv_string' with the actual CSV string data you want to display as a DataFrame\n",
    "your_csv_string = \"\"\"\n",
    "col1,col2,col3\n",
    "1,a,4.5\n",
    "2,b,4.6\n",
    "3,c,5.1\n",
    "\"\"\"\n",
    "\n",
    "display_csv(your_csv_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBZWReW1lb0k"
   },
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I1ry9_Arld0G",
    "outputId": "18c414c5-7b77-45ce-8bae-60fb1e2db985"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"Alice\",\n",
      "    \"age\": 30,\n",
      "    \"is_student\": false,\n",
      "    \"courses\": [\n",
      "        \"Math\",\n",
      "        \"Physics\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def display_json(json_string):\n",
    "    try:\n",
    "        # Parse the JSON string\n",
    "        parsed_json = json.loads(json_string)\n",
    "\n",
    "        # Pretty-print the JSON data with indentation\n",
    "        formatted_json_string = json.dumps(parsed_json, indent=4)\n",
    "\n",
    "        print(formatted_json_string)\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Could not parse the string as JSON.\")\n",
    "\n",
    "# Usage\n",
    "# Replace 'your_json_string' with the actual JSON string data you want to pretty-print\n",
    "your_json_string = '''\n",
    "{\n",
    "    \"name\": \"Alice\",\n",
    "    \"age\": 30,\n",
    "    \"is_student\": false,\n",
    "    \"courses\": [\"Math\", \"Physics\"]\n",
    "}\n",
    "'''\n",
    "\n",
    "display_json(your_json_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQcZgWpDud3z"
   },
   "source": [
    "## Count Tokens for Context Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wTMjuWHBujHY",
    "outputId": "6ec4e83d-a6fc-403c-b5db-7e52e35732b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (0.5.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from tiktoken) (2023.8.8)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/toby/src/valuestreamai/molecule-semantic-search/jupyterlab/jupyterlab-venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QAg46AaAunWV",
    "outputId": "20054750-c2f8-4db9-f7e5-4fda9c61481b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "count = num_tokens_from_string(\"tiktoken is great!\", \"cl100k_base\")\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyediting Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juding Criteria\n",
    "[From the hackathon Notion page.](https://samsungnext.notion.site/Next-Gen-AI-Hackathon-Attendee-Guide-bec2d308f82245bfbb885d1fa093521a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "judging_criteria = \"\"\"\n",
    "Judging Criteria\n",
    "\n",
    "There will be three award categories:\n",
    "\n",
    "- **Breakthrough Award:** The project that demonstrates outstanding deep core technical or architectural innovations that enable or leverage generative AI for mobile use cases.\n",
    "- **Edge Award:** The project with greatest impact that leverages only models that have been optimized and deployed locally on the device.\n",
    "- **Pioneer Award:** The project that most uniquely leverages mobile sensor, data, or services to create novel or more impactful mobile user experiences.\n",
    "\n",
    "All projects will be evaluated on the following criteria.\n",
    "\n",
    "- **Impact:** Does this project have the potential to impact millions - even billions - around the world?\n",
    "- **Creativity:** Does the project solve a problem in a differentiated or unique way?\n",
    "- **User Experience:** Does the project deliver a delightful user experience?\n",
    "- **Centrality of Generative AI:** Does generative AI play a critical role in enabling the solution?\n",
    "- **Technical feasibility:** Does the technical implementation work? If the project is not fully functional, could this approach work technically?\n",
    "- **Fidelity:** How “finished” is the project? How close is it to an alpha launch?\n",
    "\n",
    "Participants are expected share a 3-minute pitch deck including a demo and high-level architectural diagrams. We will have mentors available to help folks fine tune and prepare for the final presentations.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_proposal = \"\"\"\n",
    "﻿Proof of Concept Proposal: Automated Ontologization for Heterogeneous Experimental Data\n",
    "Toby Tobkin - Solutions Architect - toby@valuestream.ai\n",
    "\n",
    "Prepared for Forschungszentrum Jülich Department of AI and Data Analytics for Integrated Clean Energy Technologies\n",
    "Background\n",
    "A primary barrier to the widespread adoption of clean hydrogen fuel storage is discovering a practical material for Hydrogen Energy Devices. At the current rate of materials science advancement, some experts project that the discovery and adoption of requisite advanced materials such as catalysts and membrane materials could take until 2050. However, climate change and pollution are occurring rapidly, so it is critical to accelerate this R&D timeframe to 2035. The most significant barrier to accelerating this timeframe is the quantity of researcher toil required per cycle of advanced materials science (AES) experiments. The primary root cause of researcher toil is the human-inaccessibility of experimental data from applied energy materials research. This inaccessibility exists because no widely adopted ontology exists for applied energy materials research. Thus, experimental data is stored heterogeneously, effectively siloed data between scientific domains and individual labs. To overcome this, material scientists must manually de-silo from tens of millions of data points about materials and fabrication methods, drastically slowing down applied materials research. Due to intractable issues such as lab researcher turnover, we presume that AES data will remain heterogeneous without Practical Automated Ontologization for AES Heterogeneous Experimental Data (HED).\n",
    "\n",
    "Forschungszentrum Jülich Department of AI and Data Analytics for Integrated Clean Energy Technologies seeks research advancements to commercialize practical, clean hydrogen fuel storage. ValuestreamAI seeks a challenging, impactful engineering problem to solve.\n",
    "Programming Competition Venue & Scope\n",
    "The ValuestreamAI team will compete in the 2023 Samsung Gen AI programming competition in San Francisco.  The team comprises three engineers and one technical business analyst. Approximately one week of engineering preparation work is done prior to the competition. The competition is approximately ten hours of execution time. Thus, the scope must be limited while still shipping a usable product.\n",
    "Problem Statement\n",
    "Automate the classification of non-standardized CSV headers to Node Labels compliant with the Proposed EMMO Extension Ontology for Hydrogen Energy Conversion Materials Science. \n",
    "  \n",
    "Problem Selection Rationale\n",
    "Header Classification to Node Label was chosen because it is a microcosm of the AES HED problem.\n",
    "\n",
    "The problem was selected using the following process:\n",
    "1. The Client research team presented several relevant research problems. \n",
    "2. Sort by urgency to solve\n",
    "3. Tie-break by the impact of solving\n",
    "4. Filter by:\n",
    "   1. Estimated analysis scope under 70 hours\n",
    "   2. Estimated implementation scope under 30 hours\n",
    "\n",
    "Given additional time, we may also proof of concept Node Attribute classification.\n",
    "________________\n",
    "KPIs\n",
    "ValuestreamAI seeks to choose KPIs that are an accurate proxy for implementing Practical Automated Ontologization for AES HED. The following KPIs were chosen:\n",
    "\n",
    "    Precision\n",
    "\tPrecision of the classifier is paramount because a human user will distrust the inference system if they feel they cannot trust positive inferences\n",
    "\tRecall\n",
    "\tRecall determines the percent of researcher toil automated for the given subtask\n",
    "\tConfusion Matrix\n",
    "\tA slideshow-friendly version of Precision and Recall.\n",
    "\tRuntime Cost Per Million Rows\n",
    "\tDetermines the ongoing per-unit cost of testing and using the inference pipeline\n",
    "\tR&D Costs\n",
    "\tThe upfront costs. There should be an attainable cost curve for achieving useful milestones.\n",
    "\tLicensing Costs\n",
    "\tCosts related to licensing technology\n",
    "\tSuitability for On-prem Cluster\n",
    "\tHow compatible is the solution with the client research team's compute cluster?\n",
    "\tData Privacy\n",
    "\tIs data processed and stored in a secure manner that is verifyable by a layman?\n",
    "\tClient Satisfaction\n",
    "\tDoes the deliverable satisfy its intended purpose?\n",
    " \n",
    "Solution Constraints\n",
    "The proposed solution must:\n",
    "* Represent the larger problem of Practical Automated Ontologization for AES HED\n",
    "* Plausibly scale to reduce a top category of researcher toil by at least 90%\n",
    "* Be adaptable to support high-quality integration with neo4j and VIMI\n",
    "________________\n",
    "\n",
    "Hackathon Proposed Deliverables\n",
    "The deliverable is a Github Repo with the following contents:\n",
    "Jupyter Notebooks\n",
    "\tPython notebooks that reproduce the inference experiments for the problem under study.\n",
    "\tDevelopment Environment\n",
    "\tEnglish instructions and Linux scripts documenting how to reproduce the desktop environment for reproducing or extending the experiments delivered.\n",
    "\tWorkflows\n",
    "\tEnglish instructions and Linux scripts documenting how to reproduce or extend the experiments delivered.\n",
    "\tLive Training Recording\n",
    "\tUp to three hours of recorded live sessions for the client research team for training and analysis.\n",
    "\t\n",
    "\n",
    "The deliverable will have the following attributes: 1. Complementary to existing work, 2. MIT license, 3. High standard of readability\n",
    "\n",
    "Payment Terms\n",
    "ValuestreamAI requests payment only if the deliverable meets or exceeds the client research team's expectations. Payment shall be due NET60 from the day of invoice to the client research team. The requested payment amount is the approximate cost of competition preparation and travel expenses, CAD$4000. Engineering hours are granted pro bono for this project.\n",
    "\n",
    "Future Work\n",
    "The proposed deliverable is only a small slice of the larger problem of Practical Automated Ontologization for AES HED. The ValuestreamAI team is in the early stages of understanding the broader context of this research field. However, they understand the following future work is required:\n",
    "* Defining the complete engineering scope of Practical Automated Ontologization for AES HED\n",
    "* Inferring ontological relationships between heterogeneous data fields\n",
    "* Investigating the potential for collaboration with other research institutions to pool resources and data\n",
    "* Evaluating the effectiveness of the ontology in practice and making necessary adjustments based on feedback from researchers\n",
    "* Exploring the potential for machine learning algorithms to predict outcomes based on the AES data\n",
    "\n",
    "Jargon and Entities\n",
    "AES: Advanced Materials Science.\n",
    "HED: Heterogeneous Experimental Data.\n",
    "AES HED: The subproblem under research.\n",
    "Hydrogen Energy Devices: Water electrolyzers and fuel cells.\n",
    "FAIR: Findable, Accessible, Interoperable, and Reusable\n",
    "neo4j: an industry-standard graph database\n",
    "EMMO: EMMO, or the European Materials Modelling Ontology, is a versatile ontology for materials sciences developed by the European Materials Modelling Council. It consists of three levels: the top level defines real-world objects and introduces \"perspectives\" to reflect their pluralistic nature, the middle level contains specific perspectives that make EMMO applicable to various domains, and the bottom level contains ontologies of specific materials science domains. EMMO is used to standardize the knowledge representation of a domain, making it particularly useful in the context of FAIR (Findable, Accessible, Interoperable, Reusable) data generation.\n",
    "VIMI:  Virtual Materials Intelligence platform, is a system that integrates data-driven methods for materials science research. It uses the Python framework Django for seamless integration and data management. The platform is designed to handle data from fabrication workflows, measurements, and simulations and encourages researchers to share data to accelerate their research. VIMI is particularly useful in the field of energy materials, where it can assist in the screening of materials, experimental design, the optimization of workflows, and the orchestration of devices within self-driven labs. VIMI is a spin-off Project from the Institute of Energy and Climate Research, IEK-13 at Forschungszentrum Juelich.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyediting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_preamble = \"\"\"\n",
    "I am writing a talk track for a three minute video presentation for generative AI programming competition\n",
    "hosted by Samsung in San Francisco.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hackathon_judging_criteria_addressed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hackathon_judging_criteria_addressed(talk_track_md):\n",
    "    prompt = f\"\"\"\n",
    "    {prompt_preamble} \n",
    "    \n",
    "    1. Rate how well my talk track addresses each of the hackathon judging criterion\n",
    "    2. Rate how well my talk track suits each of the three winner categories\n",
    "\n",
    "    The talk track is given in <talk-track>. The judging criteria are provided in <judging-criteria>\n",
    "\n",
    "    <talk-track>\n",
    "        {talk_track_md}\n",
    "    </talk-track>\n",
    "\n",
    "    <judging-criteria>\n",
    "        {judging_criteria}\n",
    "    </judging-criteria>\n",
    "    \"\"\"\n",
    "    completion = gpt4(prompt)\n",
    "    display_md(completion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## consistent_with_research_proposal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistent_with_research_proposal(talk_track_md):\n",
    "    prompt = f\"\"\"\n",
    "    {prompt_preamble}\n",
    "    \n",
    "    Is the talk track inconsistent with the provided research proposal in any way?\n",
    "\n",
    "    The talk track is given in <talk-track>. The research proposal is given in <research-proposal>.\n",
    "\n",
    "    <talk-track>\n",
    "        {talk_track_md}\n",
    "    </talk-track>\n",
    "\n",
    "    <research-proposal>\n",
    "        {research_proposal}\n",
    "    </research-proposal>\n",
    "    \"\"\"\n",
    "    completion = gpt4(prompt)\n",
    "    display_md(completion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## technical_fact_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def technical_fact_check(talk_track_md):\n",
    "    prompt = f\"\"\"\n",
    "    {prompt_preamble}\n",
    "    \n",
    "    Are any of the claims made in the talk track potentially disputable by an educated observer? \n",
    "    Could any of the claims have the appearance of being disputable, even if they are technically accurate?\n",
    "\n",
    "    The talk track is given in <talk-track>.\n",
    "\n",
    "    <talk-track>\n",
    "        {talk_track_md}\n",
    "    </talk-track>\n",
    "    \"\"\"\n",
    "    completion = gpt4(prompt)\n",
    "    display_md(completion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate_talk_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_talk_time(talk_track_md):\n",
    "    prompt = f\"\"\"\n",
    "    {prompt_preamble}\n",
    "    \n",
    "    At 140 wpm, approximately how many seconds will the following talk track take to read?\n",
    "\n",
    "    The talk track is given in <talk-track>.\n",
    "\n",
    "    <talk-track>\n",
    "        {talk_track_md}\n",
    "    </talk-track>\n",
    "    \"\"\"\n",
    "    completion = gpt4(prompt)\n",
    "    display_md(completion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## includes_required_talking_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def includes_required_talking_points(talk_track_md):\n",
    "    prompt = f\"\"\"\n",
    "    {prompt_preamble}\n",
    "    \n",
    "    Does the talk track given include all of the talking points in <talking-points>\n",
    "\n",
    "    The talk track is given in <talk-track>.\n",
    "\n",
    "    <talk-track>\n",
    "        {talk_track_md}\n",
    "    </talk-track>\n",
    "\n",
    "    <talking-points>\n",
    "        - The high level story is this: Toby immigrated to Canada and his goal is to hit $10k in profit building AI software via face to face local sales only\n",
    "        - We pitched this pilot to the lab last Tuesday, September 12\n",
    "        - We were offered the opportunity to pitch the research lab because we hosted a local picnic for AI developers.\n",
    "        - The developers on this solution all volunteered to do this project on under 24 hour notice, paid upon payment receipt from client\n",
    "        - A key factor in getting the pilot opportunity was our differentiated open source licensing\n",
    "    </talking-points>\n",
    "    \"\"\"\n",
    "    completion = gpt4(prompt)\n",
    "    display_md(completion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## story_told_chronologically()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def story_told_chronologically(talk_track_md):\n",
    "    prompt = f\"\"\"\n",
    "    {prompt_preamble}\n",
    "    \n",
    "    Is the narrative in the talk track given chronologically in a manner that is easy for an educated audience\n",
    "    to follow?\n",
    "\n",
    "    The talk track is given in <talk-track>.\n",
    "\n",
    "    <talk-track>\n",
    "        {talk_track_md}\n",
    "    </talk-track>    \n",
    "    \"\"\"\n",
    "    completion = gpt4(prompt)\n",
    "    display_md(completion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drafting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draft 1 - Just Read The Research Proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided talk track and judging criteria, here's how your talk track addresses each of the hackathon judging criteria:\n",
       "\n",
       "1. **Impact:** Your project addresses a significant global issue - the need for clean hydrogen fuel storage. The potential impact is vast, as it could accelerate the discovery and adoption of advanced materials for Hydrogen Energy Devices. However, the talk track could be more explicit about the potential global impact. Rating: 8/10\n",
       "\n",
       "2. **Creativity:** The project proposes a unique solution to a complex problem - automating the classification of non-standardized CSV headers to Node Labels. This is a creative approach to addressing the issue of data silos in applied energy materials research. Rating: 9/10\n",
       "\n",
       "3. **User Experience:** The talk track doesn't explicitly address user experience. However, it does mention that the deliverable will have a high standard of readability, which suggests a focus on user experience. Rating: 6/10\n",
       "\n",
       "4. **Centrality of Generative AI:** The talk track doesn't explicitly mention the use of generative AI. However, the proposed solution involves automating classification, which could potentially involve generative AI. Rating: 5/10\n",
       "\n",
       "5. **Technical feasibility:** The talk track provides a detailed explanation of the problem and the proposed solution, suggesting that the approach is technically feasible. However, it doesn't provide a clear demonstration that the project is functional. Rating: 7/10\n",
       "\n",
       "6. **Fidelity:** The talk track suggests that the project is in the early stages of development, but it provides a clear plan for future work. Rating: 7/10\n",
       "\n",
       "As for the three winner categories:\n",
       "\n",
       "1. **Breakthrough Award:** The project proposes a novel solution to a significant problem, suggesting that it could be a contender for the Breakthrough Award. However, the talk track doesn't explicitly mention any deep core technical or architectural innovations. Rating: 7/10\n",
       "\n",
       "2. **Edge Award:** The talk track doesn't mention whether the models have been optimized and deployed locally on the device, so it's unclear whether the project would be a contender for the Edge Award. Rating: 5/10\n",
       "\n",
       "3. **Pioneer Award:** The project proposes a unique solution to a complex problem, suggesting that it could be a contender for the Pioneer Award. However, the talk track doesn't explicitly mention the use of mobile sensor, data, or services. Rating: 7/10\n",
       "\n",
       "Overall, the talk track provides a clear and detailed explanation of the problem and the proposed solution. However, it could be improved by explicitly addressing each of the judging criteria and winner categories."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hackathon_judging_criteria_addressed(research_proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The talk track and the research proposal are identical in content. There is no inconsistency between the two. Both documents outline the same problem, solution, and future work, and they both use the same jargon and entities. The talk track and the research proposal both provide the same information about the upcoming Samsung Gen AI programming competition, the team's preparation for the competition, and the problem they will be addressing. Therefore, there is no inconsistency between the talk track and the research proposal."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "consistent_with_research_proposal(research_proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The talk track is well-structured and provides a comprehensive overview of the proposed project. However, there are a few points that could potentially be disputed by an educated observer or could appear disputable, even if they are technically accurate:\n",
       "\n",
       "1. The claim that \"a primary barrier to the widespread adoption of clean hydrogen fuel storage is discovering a practical material for Hydrogen Energy Devices\" could be disputed. While it is true that finding a practical material is a significant challenge, there are other barriers such as the cost of production, infrastructure for distribution and storage, and safety concerns that could also be considered primary barriers.\n",
       "\n",
       "2. The statement that \"the most significant barrier to accelerating this timeframe is the quantity of researcher toil required per cycle of advanced materials science (AES) experiments\" could be seen as an oversimplification. While reducing researcher toil is important, there are other significant barriers such as funding, regulatory approval, and technological limitations that could also slow down the rate of advancement.\n",
       "\n",
       "3. The assertion that \"no widely adopted ontology exists for applied energy materials research\" could be disputed. While it may be true that there is no single, universally accepted ontology, there may be multiple ontologies in use within different research communities.\n",
       "\n",
       "4. The claim that \"material scientists must manually de-silo from tens of millions of data points about materials and fabrication methods, drastically slowing down applied materials research\" could be seen as an exaggeration. While it is true that dealing with heterogeneous data can slow down research, the claim that scientists must manually sift through tens of millions of data points could be seen as overstating the problem.\n",
       "\n",
       "5. The statement that \"the proposed solution must plausibly scale to reduce a top category of researcher toil by at least 90%\" could be seen as overly ambitious. While it is good to aim high, a 90% reduction in researcher toil is a very significant claim and could be seen as unrealistic.\n",
       "\n",
       "6. The claim that \"ValuestreamAI requests payment only if the deliverable meets or exceeds the client research team's expectations\" could be seen as risky. While this shows confidence in the team's ability to deliver, it could also be seen as a potential financial risk for ValuestreamAI.\n",
       "\n",
       "7. The statement that \"the ValuestreamAI team is in the early stages of understanding the broader context of this research field\" could be seen as a potential weakness. While it is honest, it could also raise questions about the team's ability to deliver a solution that meets the needs of the research field."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "technical_fact_check(research_proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The talk track contains approximately 1,400 words. Given a speech rate of 140 words per minute, it would take approximately 10 minutes to read the entire talk track. This is significantly longer than the three-minute time frame for the video presentation. You may need to condense the talk track or focus on key points to fit within the three-minute limit."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimate_talk_time(research_proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The talk track provided does not include all the talking points mentioned. Here's how you can incorporate the missing talking points into your talk track:\n",
       "\n",
       "1. High level story: \"Hello, my name is Toby Tobkin, a Solutions Architect at ValuestreamAI. I immigrated to Canada with a goal to hit $10k in profit building AI software via face to face local sales only. Today, I am here to present our proposal for Automated Ontologization for Heterogeneous Experimental Data.\"\n",
       "\n",
       "2. Pitching the pilot: \"We had the opportunity to pitch this pilot to the Forschungszentrum Jülich Department of AI and Data Analytics for Integrated Clean Energy Technologies last Tuesday, September 12.\"\n",
       "\n",
       "3. Opportunity to pitch: \"We were offered this opportunity because of our active involvement in the AI community. We recently hosted a local picnic for AI developers, which allowed us to connect with the research lab.\"\n",
       "\n",
       "4. Developers volunteering: \"Our dedicated team of three engineers and one technical business analyst volunteered to work on this project with less than 24 hours' notice. They are committed to delivering a high-quality product, and their payment is contingent upon receipt of payment from the client.\"\n",
       "\n",
       "5. Open source licensing: \"A key factor in securing this pilot opportunity was our unique approach to open source licensing. We believe in the power of collaboration and the sharing of knowledge, which is why our deliverable will be under an MIT license, allowing others to learn from and build upon our work.\"\n",
       "\n",
       "Remember to weave these points naturally into your presentation to maintain a coherent narrative."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "includes_required_talking_points(research_proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Yes, the narrative in the talk track is given chronologically and is easy for an educated audience to follow. It starts with the background of the problem, then moves on to the venue and scope of the competition, the problem statement, the rationale behind the problem selection, the KPIs, the solution constraints, the proposed deliverables, payment terms, and future work. It ends with a glossary of jargon and entities. This structure allows the audience to understand the context, the problem, the proposed solution, and the expected outcomes in a logical order."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "story_told_chronologically(research_proposal)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "cWp08IdDa_ok"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
